{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DatawarehouseSpark Application\") \\\n",
    "    .getOrCreate()\n",
    " \n",
    "inputFileHire ='/home/mose/Downloads/CSVS/client_hiring_dt.csv' #\"/user/user17/mosedata_proj/input/client_hiring_dt.csv\"\n",
    "#inputFileBio ='/home/mose/Downloads/CSVS/client_bio_dt.csv'  #\"/user/user17/mosedata_proj/input/client_bio_dt.csv\"\n",
    "#inputFileCom = '/home/mose/Downloads/CSVS/client_communication_dt.csv' #\"/user/user17/mosedata_proj/input/client_communication_dt.csv\"\n",
    "#inputFileAct = '/home/mose/Downloads/CSVS/client_activities_dt.csv' #\"/user/user17/mosedata_proj/input/client_activities_dt.csv\"\n",
    "#inputFileFact = '/home/mose/Downloads/CSVS/client_fact_ft.csv' #\"/user/user17/mosedata_proj/input/client_fact_ft.csv\"\n",
    "\n",
    " \n",
    "# Create DataFrame from CSV file\n",
    "dfM =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileHire)\n",
    "#dfR =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileBio)\n",
    "#dfCom =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileCom)\n",
    "#dfAct =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileAct)\n",
    "#dfFact =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileFact)\n",
    "\n",
    "\n",
    "# Print the schema of the DataFrames\n",
    "dfM.printSchema()\n",
    "dfR.printSchema()\n",
    "dfCom.printSchema()\n",
    "dfAct.printSchema()\n",
    "dfFact.printSchema()\n",
    "\n",
    "\n",
    "#dfR.groupBy('movieId').count().show(50)\n",
    "#dfM.where(\"director='Martin Brest'\").join(dfR,\"movieId\").select(\"movieId\",\"director\",\"user_name\",\"rating\").show(50)\n",
    "\n",
    "\n",
    "# Stop the Spark Session\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dataframes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dataframes.py\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DatawarehouseSpark Application\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#Input the data\n",
    "inputFileHire ='/user/user17/mosedata_proj/input/client_hiring_dt.csv'\n",
    "inputFileBio ='/user/user17/mosedata_proj/input/client_bio_dt.csv'\n",
    "inputFileCom = '/user/user17/mosedata_proj/input/client_communication_dt.csv'\n",
    "inputFileAct = '/user/user17/mosedata_proj/input/client_activities_dt.csv'\n",
    "inputFileFact = '/user/user17/mosedata_proj/input/client_fact_ft.csv'\n",
    "\n",
    "#Create data frames from sources. Tables were converted to csvs now being converted to dataframes\n",
    "dfHire =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileHire)\n",
    "dfBio =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileBio)\n",
    "dfCom =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileCom)\n",
    "dfAct =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileAct)\n",
    "dfFact =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileFact)\n",
    "\n",
    "# Print the schema of the DataFrames\n",
    "dfHire.printSchema() \n",
    "dfBio.printSchema()\n",
    "dfCom.printSchema()\n",
    "dfAct.printSchema()\n",
    "dfFact.printSchema()\n",
    "\n",
    "#Clients from different service branches\n",
    "dfBio.groupBy('service_branch__c').count().show()\n",
    "\n",
    "#Types of jobs the guys got hired in\n",
    "dfM.groupBy('job_function_hired_in__c').count().show()\n",
    "\n",
    "#Temporary objects from which sql statements are run for each dataframe\n",
    "dfHire.createOrReplaceTempView(\"dfHire_sql\")\n",
    "dfBio.createOrReplaceTempView(\"dfBio_sql\")\n",
    "dfCom.createOrReplaceTempView(\"dfCom_sql\")\n",
    "dfAct.createOrReplaceTempView(\"dfAct_sql\")\n",
    "dfFact.createOrReplaceTempView(\"dfFAct_sql\")\n",
    "\n",
    "#Mixed information from all 5 tables of the database\n",
    "spark.sql(''' Select hires.hired, bio.service_rank__c , \n",
    "              bio.service_branch__c , fact.yearsinservice, fact.reg_afterservice_years,\n",
    "              com.responsive__c, act.finalized_hhusa_revised_resume_on_file__c as resume_done\n",
    "              from dfHire_sql hires\n",
    "              inner join dfBio_sql bio on bio.id = hires.id \n",
    "              inner join dfFAct_sql fact on fact.id = hires.id\n",
    "              inner join dfCom_sql com on com.id = hires.id\n",
    "              inner join dfAct_sql act on act.id = hires.id\n",
    "              where hires.hired = \"1\"\n",
    "              \n",
    "              ''').show()\n",
    "\n",
    "#Account create date by month of the year\n",
    "spark.sql( \"\"\"SELECT count(id) , \n",
    "              Extract(Month From create_ddate) as month \n",
    "              From  dfAct_sql  \n",
    "              group by month \n",
    "              ORDER BY month ASC \"\"\").show()\n",
    "\n",
    "\n",
    "#Registration for services by year\n",
    "spark.sql( \"\"\"SELECT count(id) , \n",
    "Extract(Year From create_ddate) as year_registered \n",
    "              From  dfAct_sql  \n",
    "              group by year_registered\n",
    "              ORDER BY year_registered ASC \"\"\").show()\n",
    "\n",
    "#Hired by Service branch\n",
    "spark.sql(\"\"\" Select count(hires.id) as hired,bio.service_branch__c \n",
    "              From dfHire_sql hires \n",
    "              inner join dfBio_sql bio on bio.id = hires.id\n",
    "              Where hires.hired = 1\n",
    "              group by bio.service_branch__c\n",
    "              order by hired asc\n",
    "              \"\"\").show()\n",
    "\n",
    "#Not hired by Service Branch\n",
    "spark.sql(\"\"\" Select count(hires.id) as Not_hired,bio.service_branch__c \n",
    "              From dfHire_sql hires \n",
    "              inner join dfBio_sql bio on bio.id = hires.id\n",
    "              Where hires.hired = 0\n",
    "              group by bio.service_branch__c\n",
    "              order by Not_hired asc\n",
    "              \"\"\").show()\n",
    "\n",
    "#Hired by rank\n",
    "spark.sql(\"\"\" Select count(hires.id) as hired,bio.service_rank__c\n",
    "              From dfHire_sql hires \n",
    "              inner join dfBio_sql bio on bio.id = hires.id\n",
    "              Where hires.hired = 0\n",
    "              group by bio.service_rank__c\n",
    "              order by hired desc\n",
    "              \"\"\").show()\n",
    "\n",
    "#Prefered method of contact for the hired\n",
    "spark.sql(\"\"\" select count(com.id) as count, com.preferred_method_of_contact__c \n",
    "              from dfCom_sql com \n",
    "              inner join dfHire_sql hires on com.id = hires.id\n",
    "              where hires.hired = 1\n",
    "              group by com.preferred_method_of_contact__c \n",
    "              order by count\n",
    "          \"\"\").show()\n",
    "\n",
    "#Prefered method of contact for the Unhired\n",
    "spark.sql(\"\"\" select count(com.id) as count, com.preferred_method_of_contact__c \n",
    "              from dfCom_sql com \n",
    "              inner join dfHire_sql hires on com.id = hires.id\n",
    "              where hires.hired = 0\n",
    "              group by com.preferred_method_of_contact__c \n",
    "              order by count\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DatawarehouseSpark Application\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFileHire ='/home/mose/Downloads/CSVS/client_hiring_dt.csv' #\"/user/user17/mosedata_proj/input/client_hiring_dt.csv\"\n",
    "inputFileBio ='/home/mose/Downloads/CSVS/client_bio_dt.csv'  #\"/user/user17/mosedata_proj/input/client_bio_dt.csv\"\n",
    "inputFileCom = '/home/mose/Downloads/CSVS/client_communication_dt.csv' #\"/user/user17/mosedata_proj/input/client_communication_dt.csv\"\n",
    "inputFileAct = '/home/mose/Downloads/CSVS/client_activities_dt.csv' #\"/user/user17/mosedata_proj/input/client_activities_dt.csv\"\n",
    "inputFileFact = '/home/mose/Downloads/CSVS/client_fact_ft.csv' #\"/user/user17/mosedata_proj/input/client_fact_ft.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame from CSV file\n",
    "dfHire =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileHire)\n",
    "dfBio =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileBio)\n",
    "dfCom =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileCom)\n",
    "dfAct =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileAct)\n",
    "dfFact =  spark.read.format(\"csv\").option(\"sep\", \",\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(inputFileFact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- dsubimittedforhire: string (nullable = true)\n",
      " |-- dconfirmedforhire: string (nullable = true)\n",
      " |-- difsubmitconfirmed: integer (nullable = true)\n",
      " |-- startdate: string (nullable = true)\n",
      " |-- datdifconfirstart: integer (nullable = true)\n",
      " |-- job_type__c: string (nullable = true)\n",
      " |-- job_function_hired_in__c: string (nullable = true)\n",
      " |-- hiring_account__c: string (nullable = true)\n",
      " |-- hire_heroes_usa_confirmed_hire__c: integer (nullable = true)\n",
      " |-- hired_location__c: string (nullable = true)\n",
      " |-- hired_zip_code__c: string (nullable = true)\n",
      " |-- industry_hired_in__c: string (nullable = true)\n",
      " |-- hired_but_still_active_and_looking__c: string (nullable = true)\n",
      " |-- hired: string (nullable = true)\n",
      " |-- client_hiring_dt_id: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- client__c: integer (nullable = true)\n",
      " |-- client_type__c: string (nullable = true)\n",
      " |-- service_rank__c: string (nullable = true)\n",
      " |-- service_branch__c: string (nullable = true)\n",
      " |-- primary_military_occupational_specialty__c: string (nullable = true)\n",
      " |-- gender__c: string (nullable = true)\n",
      " |-- highest_level_of_education_completed__c: string (nullable = true)\n",
      " |-- status__c: string (nullable = true)\n",
      " |-- military_spouse_caregiver__c: string (nullable = true)\n",
      " |-- acount_createddate: string (nullable = true)\n",
      " |-- dateofserviceentry: string (nullable = true)\n",
      " |-- dateofserviceseparation: string (nullable = true)\n",
      " |-- client_bio_dt_id: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- mailingstate: string (nullable = true)\n",
      " |-- mailingpostalcode: string (nullable = true)\n",
      " |-- mailingcountry: string (nullable = true)\n",
      " |-- preferred_method_of_contact__c: string (nullable = true)\n",
      " |-- responsive__c: integer (nullable = true)\n",
      " |-- active__c: string (nullable = true)\n",
      " |-- client_communication_dt_id: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- create_ddate: string (nullable = true)\n",
      " |-- dateassignedtohhusa: string (nullable = true)\n",
      " |-- dateassignedtostaff: string (nullable = true)\n",
      " |-- dateinitialassesment: string (nullable = true)\n",
      " |-- dateresumecompleted: string (nullable = true)\n",
      " |-- dsubimittedforhire: string (nullable = true)\n",
      " |-- confirmedhiredate: string (nullable = true)\n",
      " |-- startdate: string (nullable = true)\n",
      " |-- resume_completed_by__c: string (nullable = true)\n",
      " |-- resume_tailoring_tips__c: integer (nullable = true)\n",
      " |-- finalized_hhusa_revised_resume_on_file__c: integer (nullable = true)\n",
      " |-- created_linkedin_account__c: integer (nullable = true)\n",
      " |-- client_act_dt_id: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- yearsinservice: double (nullable = true)\n",
      " |-- ringdna100__email_attempts__c: integer (nullable = true)\n",
      " |-- ringdna100__call_attempts__c: integer (nullable = true)\n",
      " |-- client_act_dt_id: string (nullable = true)\n",
      " |-- client_bio_dt_id: string (nullable = true)\n",
      " |-- client_communication_dt_id: string (nullable = true)\n",
      " |-- client_hiring_dt_id: string (nullable = true)\n",
      " |-- reg_afterservice_months: double (nullable = true)\n",
      " |-- reg_afterservice_years: double (nullable = true)\n",
      " |-- monthsinservice: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the DataFrames\n",
    "dfHire.printSchema() \n",
    "dfBio.printSchema()\n",
    "dfCom.printSchema()\n",
    "dfAct.printSchema()\n",
    "dfFact.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|service_branch__c|count|\n",
      "+-----------------+-----+\n",
      "|          Marines|13691|\n",
      "|           Spouse|    2|\n",
      "|  Merchant Marine|    1|\n",
      "|             null|37153|\n",
      "|        Air Force|13416|\n",
      "|             Army|51770|\n",
      "|      Coast Guard|  837|\n",
      "|   Not Applicable|    4|\n",
      "|             Navy|15567|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Clients from different service branches\n",
    "dfBio.groupBy('service_branch__c').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------+\n",
      "|job_function_hired_in__c| count|\n",
      "+------------------------+------+\n",
      "|    IT - Help Desk/Su...|   287|\n",
      "|    Skilled Labor/Trades|   484|\n",
      "|    Purchasing/Procur...|    73|\n",
      "|                   Sales|   697|\n",
      "|    Firefighter/EMT/E...|    71|\n",
      "|                 Science|    28|\n",
      "|    Training/Instruct...|  1113|\n",
      "|    Supply Chain/Logi...|   892|\n",
      "|             Engineering|   465|\n",
      "|    Media/Journalism/...|    54|\n",
      "|         Banking/Finance|   522|\n",
      "|              Healthcare|   900|\n",
      "|    Quality Assurance...|   238|\n",
      "|              Accounting|   171|\n",
      "|    IT - Computer Sci...|    41|\n",
      "|                    null|109255|\n",
      "|    Business Development|   196|\n",
      "|    Facilities Manage...|   165|\n",
      "|              Consultant|   456|\n",
      "|    Installation/Main...|  1223|\n",
      "+------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Types of jobs the guys got hired in\n",
    "dfM.groupBy('job_function_hired_in__c').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporary objects from which sql statements are run for each dataframe\n",
    "dfHire.createOrReplaceTempView(\"dfHire_sql\")\n",
    "dfBio.createOrReplaceTempView(\"dfBio_sql\")\n",
    "dfCom.createOrReplaceTempView(\"dfCom_sql\")\n",
    "dfAct.createOrReplaceTempView(\"dfAct_sql\")\n",
    "dfFact.createOrReplaceTempView(\"dfFAct_sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+-----------------+--------------+----------------------+-------------+-----------+\n",
      "|hired|service_rank__c|service_branch__c|yearsinservice|reg_afterservice_years|responsive__c|resume_done|\n",
      "+-----+---------------+-----------------+--------------+----------------------+-------------+-----------+\n",
      "|    1|            O-3|             Army|         11.04|                 -0.33|            1|          1|\n",
      "|    1|            E-9|             Army|         30.18|                 -0.15|            1|          1|\n",
      "|    1|            E-4|             Army|           9.8|                 -0.73|            1|          1|\n",
      "|    1|            E-4|             Army|          2.81|                  0.43|            1|          1|\n",
      "|    1|            E-4|          Marines|          4.47|                  4.45|            1|          1|\n",
      "|    1|            O-2|             Army|          4.38|                 -0.51|            1|          1|\n",
      "|    1|            O-3|             Army|         11.03|                 -0.09|            1|          1|\n",
      "|    1|            E-8|             Army|         20.59|                  2.14|            1|          1|\n",
      "|    1|            E-7|             Army|         22.27|                 -0.42|            1|          1|\n",
      "|    1|            E-7|             Army|         20.01|                 -0.53|            1|          1|\n",
      "|    1|            O-3|             Army|          7.89|                 -0.41|            1|          1|\n",
      "|    1|            E-5|             Navy|          7.94|                 -0.31|            1|          1|\n",
      "|    1|            O-3|             Army|         16.89|                  1.54|            1|          1|\n",
      "|    1|            E-9|        Air Force|         29.82|                 -0.62|            1|          1|\n",
      "|    1|            E-7|        Air Force|         20.06|                  3.47|            1|          1|\n",
      "|    1|            W-1|             Army|         41.99|                -23.56|            1|          1|\n",
      "|    1|            O-3|             Army|         20.83|                 -0.82|            1|          1|\n",
      "|    1|            O-3|             Army|          4.08|                  0.03|            1|          1|\n",
      "|    1|            E-6|             Army|           6.1|                 -0.33|            1|          1|\n",
      "|    1|            E-4|             Navy|          7.09|                  8.58|            1|          1|\n",
      "+-----+---------------+-----------------+--------------+----------------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Mixed information from all 5 tables of the database\n",
    "spark.sql(''' Select hires.hired, bio.service_rank__c , \n",
    "              bio.service_branch__c , fact.yearsinservice, fact.reg_afterservice_years,\n",
    "              com.responsive__c, act.finalized_hhusa_revised_resume_on_file__c as resume_done\n",
    "              from dfHire_sql hires\n",
    "              inner join dfBio_sql bio on bio.id = hires.id \n",
    "              inner join dfFAct_sql fact on fact.id = hires.id\n",
    "              inner join dfCom_sql com on com.id = hires.id\n",
    "              inner join dfAct_sql act on act.id = hires.id\n",
    "              where hires.hired = \"1\"\n",
    "              \n",
    "              ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|count(id)|month|\n",
      "+---------+-----+\n",
      "|    11982|    1|\n",
      "|     9626|    2|\n",
      "|    10152|    3|\n",
      "|    12579|    4|\n",
      "|    10978|    5|\n",
      "|    10672|    6|\n",
      "|    10815|    7|\n",
      "|    11912|    8|\n",
      "|    10845|    9|\n",
      "|    11866|   10|\n",
      "|    12022|   11|\n",
      "|     8992|   12|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Account create date by month of the year\n",
    "spark.sql( \"\"\"SELECT count(id) , \n",
    "              Extract(Month From create_ddate) as month \n",
    "              From  dfAct_sql  \n",
    "              group by month \n",
    "              ORDER BY month ASC \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+\n",
      "|count(id)|year_registered|\n",
      "+---------+---------------+\n",
      "|     2825|           2007|\n",
      "|     2571|           2008|\n",
      "|     1769|           2009|\n",
      "|     2255|           2010|\n",
      "|     2732|           2011|\n",
      "|     4258|           2012|\n",
      "|    13128|           2013|\n",
      "|    13593|           2014|\n",
      "|    13248|           2015|\n",
      "|    25175|           2016|\n",
      "|    22933|           2017|\n",
      "|    26448|           2018|\n",
      "|     1506|           2019|\n",
      "+---------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Registration for services by year\n",
    "spark.sql( \"\"\"SELECT count(id) , \n",
    "Extract(Year From create_ddate) as year_registered \n",
    "              From  dfAct_sql  \n",
    "              group by year_registered\n",
    "              ORDER BY year_registered ASC \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|hired|service_branch__c|\n",
      "+-----+-----------------+\n",
      "|    1|   Not Applicable|\n",
      "|  170|      Coast Guard|\n",
      "| 1145|             null|\n",
      "| 2423|          Marines|\n",
      "| 2879|        Air Force|\n",
      "| 3055|             Navy|\n",
      "|10417|             Army|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hired by Service branch\n",
    "spark.sql(\"\"\" Select count(hires.id) as hired,bio.service_branch__c \n",
    "              From dfHire_sql hires \n",
    "              inner join dfBio_sql bio on bio.id = hires.id\n",
    "              Where hires.hired = 1\n",
    "              group by bio.service_branch__c\n",
    "              order by hired asc\n",
    "              \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+\n",
      "|Not_hired|service_branch__c|\n",
      "+---------+-----------------+\n",
      "|        2|   Not Applicable|\n",
      "|      667|      Coast Guard|\n",
      "|     9382|             null|\n",
      "|    10524|        Air Force|\n",
      "|    11260|          Marines|\n",
      "|    12500|             Navy|\n",
      "|    41314|             Army|\n",
      "+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Not hired by Service Branch\n",
    "spark.sql(\"\"\" Select count(hires.id) as Not_hired,bio.service_branch__c \n",
    "              From dfHire_sql hires \n",
    "              inner join dfBio_sql bio on bio.id = hires.id\n",
    "              Where hires.hired = 0\n",
    "              group by bio.service_branch__c\n",
    "              order by Not_hired asc\n",
    "              \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+\n",
      "|hired|service_rank__c|\n",
      "+-----+---------------+\n",
      "|19140|            E-4|\n",
      "|17426|            E-5|\n",
      "|10524|            E-6|\n",
      "| 9597|           null|\n",
      "| 8914|            E-7|\n",
      "| 4207|            E-3|\n",
      "| 3604|            E-8|\n",
      "| 3116|            O-3|\n",
      "| 1637|            O-4|\n",
      "| 1450|            E-9|\n",
      "| 1438|            O-5|\n",
      "|  950|            O-2|\n",
      "|  900|            E-2|\n",
      "|  623|            O-6|\n",
      "|  543|            E-1|\n",
      "|  493|            W-3|\n",
      "|  352|            W-2|\n",
      "|  339|            W-4|\n",
      "|  240|            O-1|\n",
      "|   71|            W-5|\n",
      "+-----+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Hired by rank\n",
    "spark.sql(\"\"\" Select count(hires.id) as hired,bio.service_rank__c\n",
    "              From dfHire_sql hires \n",
    "              inner join dfBio_sql bio on bio.id = hires.id\n",
    "              Where hires.hired = 0\n",
    "              group by bio.service_rank__c\n",
    "              order by hired desc\n",
    "              \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------+\n",
      "|count|preferred_method_of_contact__c|\n",
      "+-----+------------------------------+\n",
      "|    7|                          Mail|\n",
      "|   23|                      LinkedIn|\n",
      "|  158|                          Text|\n",
      "| 1892|                          null|\n",
      "| 2626|                        E-Mail|\n",
      "|15384|                     Telephone|\n",
      "+-----+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prefered method of contact for the hired\n",
    "spark.sql(\"\"\" select count(com.id) as count, com.preferred_method_of_contact__c \n",
    "              from dfCom_sql com \n",
    "              inner join dfHire_sql hires on com.id = hires.id\n",
    "              where hires.hired = 1\n",
    "              group by com.preferred_method_of_contact__c \n",
    "              order by count\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------+\n",
      "|count|preferred_method_of_contact__c|\n",
      "+-----+------------------------------+\n",
      "|   28|                          Mail|\n",
      "|   33|                      LinkedIn|\n",
      "|  378|                          Text|\n",
      "|12405|                        E-Mail|\n",
      "|31506|                          null|\n",
      "|41299|                     Telephone|\n",
      "+-----+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prefered method of contact for the Unhired\n",
    "spark.sql(\"\"\" select count(com.id) as count, com.preferred_method_of_contact__c \n",
    "              from dfCom_sql com \n",
    "              inner join dfHire_sql hires on com.id = hires.id\n",
    "              where hires.hired = 0\n",
    "              group by com.preferred_method_of_contact__c \n",
    "              order by count\n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
